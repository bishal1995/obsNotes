Anatomy of a Flink Cluster
![[processes.svg]]
The Flink runtime consists of two types of processes: a _JobManager_ and one or more _TaskManagers_.The _Client_ is not part of the runtime and program execution, but is used to prepare and send a dataflow to the JobManager. After that, the client can disconnect (_detached mode_), or stay connected to receive progress reports (_attached mode_). 
* JobManager :  The _JobManager_ has a number of responsibilities related to coordinating the distributed execution of Flink Applications: it decides when to schedule the next task (or set of tasks), reacts to finished tasks or execution failures, coordinates checkpoints, and coordinates recovery on failures, among others. This process consists of three different components:
	* ResourceManager : The _ResourceManager_ is responsible for resource de-/allocation and provisioning in a Flink cluster. Flink implements multiple ResourceManagers for different environments and resource providers such as YARN, Kubernetes and standalone deployments.
	* Dispatcher : The _Dispatcher_ provides a REST interface to submit Flink applications for execution and starts a new JobMaster for each submitted job. It also runs the Flink WebUI to provide information about job executions.
	* JobMaster : A _JobMaster_ is responsible for managing the execution of a single [JobGraph](https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/concepts/glossary/#logical-graph). Multiple jobs can run simultaneously in a Flink cluster, each having its own JobMaster.
* TaskManager : The _TaskManagers_ (also called _workers_) execute the tasks of a dataflow, and buffer and exchange the data streams. The smallest unit of resource scheduling in a TaskManager is a task _slot_. The number of task slots in a TaskManager indicates the number of concurrent processing tasks. Note that multiple operators may execute in a task slot. Each worker (TaskManager) is a _JVM process_, and may execute one or more subtasks in separate threads.
	* Tasks and Operator Chains
		* For distributed execution, Flink _chains_ operator subtasks together into _tasks_. Each task is executed by one thread. Chaining operators together into tasks is a useful optimization: it reduces the overhead of thread-to-thread handover and buffering, and increases overall throughput while decreasing latency.
		* ![[tasks_chains.svg]]
	* Task Slots and Resources
		* Each _task slot_ represents a fixed subset of resources of the TaskManager. A TaskManager with three slots, for example, will dedicate 1/3 of its managed memory to each slot. Note that no CPU isolation happens here; currently slots only separate the managed memory of tasks. Tasks in the same JVM share TCP connections (via multiplexing) and heartbeat messages.Flink allows subtasks to share slots even if they are subtasks of different tasks, so long as they are from the same job.
		* ![[slot_sharing.svg]]
* Flink application execution
	* A _Flink Application_ is any user program that spawns one or multiple Flink jobs from its `main()` method. The execution of these jobs can happen in a local JVM (`LocalEnvironment`) or on a remote setup of clusters with multiple machines (`RemoteEnvironment`).The jobs of a Flink Application can either be submitted to a long-running [Flink Session Cluster](https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/concepts/glossary/#flink-session-cluster), or a [Flink Application Cluster](https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/concepts/glossary/#flink-application-cluster)
		* Flink application cluster : Dedicated Flink cluster that only executes jobs from one Flink Application and where the `main()` method runs on the cluster rather than the client. The job submission is a one-step process: you donâ€™t need to start a Flink cluster first and then submit a job to the existing cluster session; instead, you package your application logic and dependencies into a executable job JAR and the cluster entrypoint (`ApplicationClusterEntryPoint`) is responsible for calling the `main()` method to extract the JobGraph.
		* Flink session cluster : The client connects to a pre-existing, long-running cluster that can accept multiple job submissions. Even after all jobs are finished, the cluster (and the JobManager) will keep running until the session is manually stopped.